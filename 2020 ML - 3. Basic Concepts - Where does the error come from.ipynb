{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Basic_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where does the error come from?\n",
    "\n",
    "## Where does the error come from?\n",
    "\n",
    "* 越复杂的model，不一定在testing data上给你越低的error.\n",
    "* 今天我们要讨论的问题就是，这个error来自什么地方。\n",
    "* 其实，error有两个来源：\n",
    "  * 一个来自于bias\n",
    "  * 一个来自于variance \n",
    "* __了解这个error的来源是非常重要的。__ 因为你常常做一个machine learning,做完之后就发现，得到一个error rate,比如说60%的error rate, 如果你没有什么方向，毫无头绪的乱改进，你就没有效率。\n",
    "* 如果你今天可以诊断你的error的来源，比如说error可以分成两种，一种来自于bias,一种来自于variance,你就可以挑选合适的方法来改进你的model.\n",
    "\n",
    "![](Basic_01.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Estimator\n",
    "\n",
    "* task: 我们要找一个function,去做宝可梦进化后的cp值。这个function,理论上有一个最佳的function,这个最佳的function写成$\\hat f$.\n",
    "* 但是，这个最佳的function,我们是不知道的。\n",
    "* 我们能做的是，我们有一些traning data, 根据我们的traning data所找到的最好的function $\\star f$. $\\star f$ is a estimator of $\\hat f$.\n",
    "* $\\star f$和$\\hat f$之间有一段距离。这段距离来自于两件事情 -\n",
    "  * 有可能来自于Bias\n",
    "  * 也有可能来自于Variance \n",
    "\n",
    "\n",
    "![](Basic_02.png)\n",
    "\n",
    "## 2. Bias and Variance of Estimator\n",
    "\n",
    "![](Basic_03.png)\n",
    "![](Basic_04.png)\n",
    "![](Basic_05.png)\n",
    "\n",
    "\n",
    "## 3. Bias and Variance of Estimator\n",
    "\n",
    "* 怎么知道estimator是不是bias呢？假设你可以做很多次实验，你把$\\star f$的期望值算出来，$\\bar f$。假设我们用右下角的例子来看，estimator和$\\bar f$之间有一个很大的距离，就没有瞄准，这是bias.\n",
    "* 你瞄准了，但是还是有便宜，所以每一次找出来的$\\star f$是不一样的。而这个$\\star f$跟你瞄准的位置，也就是$\\star f$的期望值，和$\\bar f$中间的距离，是variance.\n",
    "* 所以你的错误来自于两件事情:一件事情是你的bias有多大，另外一件事情，是variance有多大。\n",
    "* 最理想的状况是，我们期待的是，你同时没有bias,variance又很小。这样你每次做实验，找出来的$\\star f$都是好的。\n",
    "* 如果你遇到一个状况，你的bias很大，但是variance很小，那你每一次找的$\\star f$都很像，但是都集中在这个错的位置，（离目标function很远的位置）\n",
    "* 也有可能你找出来的function,是没有bias，但是variance很大。（如右上图）。\n",
    "* 所以，error来自于两个地方，一个是你瞄准的位置在哪里，另外一个是你的variance有多大。\n",
    "* 有人可能会问一个问题，你不是只能做一次实验吗？你怎么能找很多个function呢？你怎么知道它的variance和bias有多大呢？你怎么能找很多$\\star f$呢？\n",
    "\n",
    "\n",
    "![](Basic_06.png)\n",
    "\n",
    "\n",
    "## 4. Parallel Universes\n",
    "\n",
    "* 我们用不同的training data,即使用相同的model,我们得到的$\\star f$也是不一样的。\n",
    "\n",
    "![](Basic_07.png)\n",
    "![](Basic_08.png)\n",
    "\n",
    "## 5. Parallel Universes - looking for $\\star f$\n",
    "\n",
    "* 我们用不同的training data,即使用相同的model,我们得到的$\\star f$也是不一样的。\n",
    "\n",
    "![](Basic_09.png)\n",
    "\n",
    "\n",
    "## 6. Variance\n",
    "* 简单的model,就是只有考虑一次方的model,它是比较集中的。\n",
    "* 如果考虑5次方的话，那么散布就非常的广。\n",
    "* 所以，简单的model,它的variance是比较小的，就像是射击的时候，你每次射中的地方都是差不多的。\n",
    "* 如果换一个比较复杂的model,它的散布就很开，variance很大，每一条直线都长的很不像。\n",
    "* 为什么比较复杂的model,它的散布就比较开呢？为什么比较简单的model,它的散布就比较小呢？因为，简单的model它比较不会受你的data的影响，它的variance就很小。\n",
    "\n",
    "\n",
    "![](Basic_10.png)\n",
    "\n",
    "\n",
    "## 7. Bias\n",
    "* Bias: if we average all the function, is it close to $\\hat f$?\n",
    "* 如果是一个大的bias的话，意思就是说，我们把今天所有的function star 平均起来，你得到的$\\bar f$，它跟靶心$\\hat f$是有一段距离的。\n",
    "* 如果是小的bias的话，意思是说你的function star分散的很开，你要找它的平均值，它的平均值，跟靶心是接近的。不管它散布的有多开，它的平均值和靶心是接近的。这叫做small bias.\n",
    "* 如果是一个比较简单的model,会有比较大的bias,如果是比较复杂的model,会有比较大的variance,但是比较小的bias.\n",
    "\n",
    "![](Basic_11.png)\n",
    "\n",
    "## 8. Bias and Variances\n",
    "\n",
    "* 在下图中，从左到右，bias是在逐渐减少的，说明model本身在不断的改进（瞄的越来越准）\n",
    "* 从左到右，variance是在逐渐增大的，\n",
    "* 当bias和variance同时被考虑的时候，就是蓝色的那一条线，也就是说，在某一个地方，可以找到一个平衡的点。\n",
    "* 但是，当model越来越复杂的时候，variance会增加的比较快，error就会变得很大。\n",
    "* 所以，今天如果是一个variance很大的情形，那么这个状况就是overfitting\n",
    "* 如果你的error来自于bias很大的情形，那么合格状况就是underfitting.\n",
    "\n",
    "![](Basic_12.png)\n",
    "\n",
    "\n",
    "## 9. What to do with large bias?\n",
    "* Diagnosis: 如何detect出来，你的error是来自于bias,还是来自于variance?\n",
    " * 如果你的model不能很好的fit training example，那么代表你的bias是比较大的。(underfitting)\n",
    " * 如果你的model能够很好的fit traning data,但是在test data上得到的error非常大，那么这是variance比较大的情形。（overfitting）\n",
    " \n",
    " \n",
    "* __如果是bias大__，那么我们需要redesign我们的model\n",
    " 1. 加入更多的features\n",
    " 2. 或者是让model更加复杂\n",
    "\n",
    "\n",
    "* __如果是variance大__, \n",
    " 1. 那么我们需要增加Data(very effective, but not always practical)\n",
    " 2. Regularization，但是有可能会伤害到bias\n",
    "\n",
    "\n",
    "![](Basic_13.png)\n",
    "![](Basic_14.png)\n",
    "\n",
    "## 10. Model Selection\n",
    "\n",
    "* 我们经常需要在bias和variance之间做一些平衡\n",
    "* What we should NOT DO - \n",
    "\n",
    "![](Basic_15.png)\n",
    "\n",
    "\n",
    "# 11. Homework\n",
    "\n",
    "* 用training dataset train出来三个models\n",
    "* 为了确定哪一个model是最好的，于是用Test data来测试，发现model 3的err最小，是0.5. 于是选了model 3.\n",
    "* 但是实际上，private dataset是不可见的，error也是看不见的，而且这个error通常大于public testing set上的error. \n",
    "* so this is what we should NOT DO.\n",
    "\n",
    "![](Basic_16.png)\n",
    "\n",
    "\n",
    "# 12. Cross Validation\n",
    "\n",
    "* 正确的做法是，把training dataset拆分成training set和validation set。一组用来traning model,另外一个组，不用它来train model，但是用它来选model. \n",
    "* But not recommend - 因为public testing error过大，而重新调整原model.因为这个过程，引入并且考虑了public dataset的bias.\n",
    "\n",
    "\n",
    "![](Basic_17.png)\n",
    "\n",
    "# 13. N-fold Cross Validation\n",
    "\n",
    "![](Basic_18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
